{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4e1bda-201a-4ead-93f7-c7175dc48779",
   "metadata": {},
   "source": [
    "# Transcriptions\n",
    "PyData Global 2021 | @BradenRiggs1\n",
    "\n",
    "Learn more about Azure Cognitive Services:https://azure.microsoft.com/en-us/services/cognitive-services/\n",
    "\n",
    "Learn more about PocketSphinx: https://pypi.org/project/pocketsphinx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105f036-4af0-4c48-8b2e-1f3cb7714fe8",
   "metadata": {},
   "source": [
    "## Method 1: Azure Cognitive Services Speech-to-text (Cost)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2df4e8-580c-46d3-b91e-c3622b4a1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"\"\n",
    "presigned_blob_url = \"\"\n",
    "presigned_contaner_url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afc597-fa8f-4262-baab-aefaa1b23ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(API_KEY,AUDIO_FILE,CONTAINER_OUTPUT):\n",
    "    \"\"\"\n",
    "    Creates a transcription job on the Azure Cognitive Services server.\n",
    "    Inputs:\n",
    "       API_KEY: The Cognitive Service Transcription API key required for authenticating jobs.\n",
    "       AUDIO_FILE: The SAS URL that points to the file for transcription.\n",
    "       CONTAINER_OUTPUT: The SAS URL that directs the Azure server to where the transcription should go.\n",
    "    Returns: \n",
    "       Post response.\n",
    "    \"\"\"\n",
    "\n",
    "    #Submit a transcription job\n",
    "    headers = {\"Content-Type\": \"application/json\",\"Ocp-Apim-Subscription-Key\": API_KEY}\n",
    "    body = {\"contentUrls\": [AUDIO_FILE],  \n",
    "            \"properties\": {\n",
    "                \"diarizationEnabled\": False,\n",
    "                \"wordLevelTimestampsEnabled\": False,\n",
    "                \"punctuationMode\": \"DictatedAndAutomatic\",\n",
    "                \"profanityFilterMode\": \"Masked\",\n",
    "                \"destinationContainerUrl\": CONTAINER_OUTPUT\n",
    "            },\n",
    "            \"locale\": \"en-US\",\n",
    "            \"displayName\": \"Transcribing media in a Dolby.io-Azure mediaflow\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://westus.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions\", headers=headers, json=body)\n",
    "    response.raise_for_status()\n",
    "    print(\"Transcription Job Created Successfully, Check Input Container for Transcription...\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58377b82-34ac-4ebe-a233-debddc8e4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "start(api_key, presigned_blob_url, presigned_contaner_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6812fdc-7e70-41cf-b5ae-6a358fc26cd8",
   "metadata": {},
   "source": [
    "## Method 2: SpeechRecognition with pocketsphinx 0.1.15 (Free)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b89c94-e1ca-44d9-b0f3-56da00db874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999df786-bb5d-4507-80ce-3b4286b56a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "AUDIO_FILE = \"raw_audio/raw_sports/1.wav\"\n",
    "                                      \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(\"Transcription: \" + r.recognize_sphinx(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e86dca-c358-4721-9a48-ba1e7a196268",
   "metadata": {},
   "source": [
    "## Like this project and have some ideas of your own?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72906205-e4a5-4fd2-a42a-6bf12e7fab0e",
   "metadata": {},
   "source": [
    "You can submit your ideas here:https://go.dolby.io/pydata-2021\n",
    "\n",
    "The Dolby.io team will be picking their **5 favorite Analyze API ideas live during the workshop** and an **additional 5 favorite Analyze API ideas after November 7th** so add some of your favorite ideas for how you can use our API and win some free API minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43a170-c80f-4e06-9d47-eacfa2cd5f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
